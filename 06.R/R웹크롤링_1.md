# R 웹크롤링 (11) rvest 패키지

## HTML 로드

```R
url <- "http:// ... "		# 크롤링할 페이지 URL
text <- read_html(url)		# 해당 URL의 html을 받아온다
text
```

<br>

## 스크래핑을 위한 주요 함수

* `html_nodes()` :  DOM 객체를 찾아오는 함수(해당되는 객체 모두)
* `html_node()` :  DOM 객체를 찾아오는 함수(해당되는 첫 번째 객체만)
* `html_text(x, trim=F)` :  
* `html_attrs(x)` :  속성값을 가져옴(해당되는 객체 모두)
*  `html_attr(x)` :  속성값을 가져옴(해당되는 첫 번째 객체만)

**→ 만약 해당되는 객체가 없을 경우 `NA` 반환**

<br>

**사용 예시**

```R
nodes <- html_nodes(text, "div")
####### 결과 예시 #######
# {xml_nodeset (3)}
# [1] <div style="background-color:yellow">테스트입니다1</div>
# [2] <div>테스트입니다2</div>
```

<br>

```R
nodes <- html_nodes(text, xpath="//*[@id='old_content']/table/td[2]/text()")
nodes <- html_text(nodes, trim=TRUE)
nodes
```

* `trim` :  "/n" 이나 "/t" 같은 문자에 따라 잘라주는 옵션



<br>

**참고) XPath**

* [XPath 기본 표현식]((https://github.com/lsGee/TIL/blob/master/05.Web/web_xpath_1.md))